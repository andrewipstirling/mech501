{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Inverted Pendulum Control\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Control theory, is centred around the behaviour of dynamic systems, and how as\n",
    "engineers we can force it to behave in a certain way. In the context of Mechanical Engineering, these systems could vary from robotics, to automotive systems, to aerospace and HVAC applications. A large portion of Control design is spent modelling the system or \"plant\". This requires a good grasp of the system's mechanics, understanding all variables that may influence its behaviour. For complex systems, these dynamics are highly non-linear, while exhibiting large degrees of freedom. In such applications, traditional control techniques may struggle to produce reliable and accurate behaviour. Moreover, we may not even be able to model the system, making any form of controller design impossible. \n",
    "\n",
    "In these cases, we can make use of Reinforcement Learning (RL) for controlling such complex systems. RL operates in a model-free fashion, meaning we are not required to have an explicit model of a system's behaviour given various inputs. Using RL, we can effectively sidestep all the disadvantages of model-based controller design. RL generally consists of an agent who, through interacting with an environment, can learn to map various situations to actions. Specifically, the environment provides responses to each a agent's action, using these responses and rewards dependent on various states of the agent, we can condition the agent's decisions towards optimal states. In class, the problems we solved required the action and/or the state to be discretizable. However, for continuous systems, this may not be possible or if it is, it raises the question to what resolution we look to discretize the space or actions. The Soft Actor-Critic architecture is a form of RL that looks to solve this problem. \n",
    "\n",
    "In this project, we look to investigate RL's applications and performance in control settings. Specifically, we look to investigate the Soft Actor-Critic (SAC) architecture's ability to control a continuous system, consisting of an inverted pendulum on a cart. \n",
    "\n",
    "\n",
    "### The Inverted Pendulum\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Control Theory is a field of engineering and mathematics that deals with the behavior of dynamic systems. In the context of Mechanical Engineering, dynamic systems are prevalent and can be found in various applications, ranging from robotics and automation to aerospace and automotive systems.\n",
    "\n",
    "\n",
    "\n",
    "This document explores the implementation of Soft Actor-Critic (SAC), a state-of-the-art reinforcement learning algorithm. SAC is known for its ability to handle continuous action spaces and incorporate entropy regularization, encouraging exploration in addition to exploitation.\n",
    "\n",
    "The provided code snippets demonstrate key components of the SAC algorithm, including training and testing procedures. We'll break down each section to understand how the agent learns and evaluates its policy in a given environment.\n",
    "\n",
    "Let's dive into the details of the SAC algorithm implementation and explore how it can be used to train an intelligent agent for decision-making in complex environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
